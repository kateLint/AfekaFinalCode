# ğŸ“˜ Kickstarter Paraphrasing Optimizer

A research-grade tool that uses **paraphrasing, embeddings, and machine learning** to improve Kickstarter campaign success through better narrative phrasing.

---

## ğŸš€ Features

- âš™ï¸ **Paraphrase Generation** with `humarin/chatgpt_paraphraser_on_T5_base`
- ğŸ“Š **Success Evaluation** using a pretrained LightGBM classifier
- ğŸ“ **Keyphrase Extraction** via KeyBERT
- ğŸ§  **Coherence Scoring** using MiniLM embeddings
- ğŸ” **Bayesian Hyperparameter Optimization** with Optuna
- âš¡ **Quick Suggestions** using preset decoding strategies
- ğŸ“‰ **Visual Success Bars** for user-friendly feedback

---

## ğŸ–¥ï¸ Usage

### 1. Clone and install requirements:
```bash
git clone <your-repo-url>
cd kickstarter-paraphraser
pip install -r requirements.txt
```

### 2. Run the main script:
```bash
python paraphrasing_optimizer.py
```

---

## ğŸ“ File Structure

```text
.
â”œâ”€â”€ paraphrasing_optimizer.py     # Main script
â”œâ”€â”€ lightgbm_kickstarter_success_model.pkl
â”œâ”€â”€ lightgbm_feature_columns.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ (optional) new_projects.json
```

---

## ğŸ“¥ Inputs

A dictionary-style project input with at least:
- `story`: the main narrative
- `risks`: the risk section
- Structured features: `goal`, `rewardscount`, `category_Web_Development`, etc.

---

## ğŸ“¤ Outputs

- Console visualization of:
  - Success probabilities
  - Score bars
  - Top paraphrases
  - Optimization reports
- Optional: Save results to CSV (planned)

---

## ğŸ“š Models Used

| Model                                 | Purpose                       |
|--------------------------------------|-------------------------------|
| `humarin/chatgpt_paraphraser_on_T5_base` | Paraphrase generation         |
| `sentence-transformers/all-MiniLM-L12-v2` | Embeddings + Coherence Check |
| LightGBM classifier                  | Success prediction           |
| KeyBERT                              | Keyphrase extraction         |

---

## âš™ï¸ Optimization

Uses Optuna to find best decoder parameters:
- `top_k`: token diversity
- `top_p`: nucleus sampling
- `temperature`: randomness

All trials filtered by coherence threshold (default: 0.6).

---

## ğŸ›  Future Improvements

- [ ] Save best paraphrases to CSV
- [ ] Add Gradio interface
- [ ] Extend to pledged ratio prediction
- [ ] Add support for Hebrew translation/analysis

---

## ğŸ“œ License

MIT License. For academic or research use, please cite appropriately.

---

## âœ¨ Acknowledgments

- Hugging Face Transformers
- Sentence-Transformers
- Optuna team
- Kickstarter for the dataset
