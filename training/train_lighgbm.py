import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score
import joblib
import json

# === 1. ×˜×¢×™× ×ª ×”× ×ª×•× ×™× ===
json_path = "/Users/kerenlint/Projects/Afeka/all_models/all_good_projects_with_modernbert_embeddings_enhanced_with_miniLM12.json"
df = pd.read_json(json_path)

# === 2. ×™×¦×™×¨×ª ×¢××•×“×ª ×™×¢×“ ×‘×™× ××¨×™×ª (1=successful, 0=failed) ===
df["success"] = df["state"].map({"successful": 1, "failed": 0})
df = df.dropna(subset=["success"])

# === 2.5. ×¤×™×¨×•×§ MiniLM Embeddings ===
assert df["story_miniLM"].apply(lambda x: isinstance(x, list)).all(), "âŒ ×™×© story_miniLM ×©×œ× ×¨×©×™××”"
assert df["risks_miniLM"].apply(lambda x: isinstance(x, list)).all(), "âŒ ×™×© risks_miniLM ×©×œ× ×¨×©×™××”"

story_emb_df = pd.DataFrame(df["story_miniLM"].tolist(), index=df.index)
story_emb_df.columns = [f"story_miniLM_{i}" for i in range(story_emb_df.shape[1])]
risks_emb_df = pd.DataFrame(df["risks_miniLM"].tolist(), index=df.index)
risks_emb_df.columns = [f"risks_miniLM_{i}" for i in range(risks_emb_df.shape[1])]

df = df.drop(columns=["story_miniLM", "risks_miniLM"])
df = pd.concat([df, story_emb_df, risks_emb_df], axis=1)

# === 3. ×—×™×œ×•×¥ ×¤×™×¦'×¨×™× ×××‘× ×™× ××§×•× × ×™× ===
def safe_get(d, path, default=np.nan):
    try:
        for key in path:
            d = d.get(key, {})
        return d if isinstance(d, (int, float)) and d is not None else default
    except Exception:
        return default

readability_keys = {
    "Flesch Reading Ease": "Flesch_Reading_Ease",
    "Flesch-Kincaid Grade Level": "Flesch_Kincaid_Grade",
    "Gunning Fog Index": "Gunning_Fog",
    "SMOG Index": "SMOG",
    "Automated Readability Index": "ARI"
}

df["Story_Avg_Sentence_Length"] = df["Story Analysis"].apply(lambda x: safe_get(x, ["Average Sentence Length"]))
df["Risks_Avg_Sentence_Length"] = df["Risks and Challenges Analysis"].apply(lambda x: safe_get(x, ["Average Sentence Length"]))

for long_key, short_key in readability_keys.items():
    df[f"Story_{short_key}"] = df["Story Analysis"].apply(lambda x: safe_get(x, ["Readability Scores", long_key]))
    df[f"Risks_{short_key}"] = df["Risks and Challenges Analysis"].apply(lambda x: safe_get(x, ["Readability Scores", long_key]))

df["Story_GCI"] = pd.to_numeric(df.get("Story GCI", np.nan), errors="coerce")
df["Risks_GCI"] = pd.to_numeric(df.get("Risks and Challenges GCI", np.nan), errors="coerce")

# === 4. ×—×™×©×•×‘ preparation_days ===
df["created_at"] = pd.to_datetime(df["created_at"], unit="ms", errors="coerce")
df["launched_at"] = pd.to_datetime(df["launched_at"], unit="ms", errors="coerce")
df["preparation_days"] = (df["launched_at"] - df["created_at"]).dt.days

# === 5. ×™×¦×™×¨×ª category_Web_Combined ===
df["category_Web_Combined"] = (
    df.get("category_Web", False).fillna(False).astype(bool) |
    df.get("category_Web Development", False).fillna(False).astype(bool)
).astype(int)

# === 6. ×”×’×“×¨×ª ×¨×©×™××ª ×¤×™×¦'×¨×™× ===
base_features = [
    "projectFAQsCount", "rewardscount", "project_length_days", "preparation_days",
    "Story_Avg_Sentence_Length", "Story_Flesch_Reading_Ease", "Story_Flesch_Kincaid_Grade",
    "Story_Gunning_Fog", "Story_SMOG", "Story_ARI",
    "Risks_Avg_Sentence_Length", "Risks_Flesch_Reading_Ease", "Risks_Flesch_Kincaid_Grade",
    "Risks_Gunning_Fog", "Risks_SMOG", "Risks_ARI",
    "Story_Positive", "Story_Neutral", "Story_Negative", "Story_Compound",
    "Risks_Positive", "Risks_Neutral", "Risks_Negative", "Risks_Compound",
    "Story_GCI", "Risks_GCI",
    "category_Web_Combined"
]

category_features = [
    col for col in df.columns if col.startswith("category_") and col != "category_Technology"
]

story_minilm_features = [col for col in df.columns if col.startswith("story_miniLM")]
risks_minilm_features = [col for col in df.columns if col.startswith("risks_miniLM")]

all_features = base_features + category_features + story_minilm_features + risks_minilm_features
all_features = list(dict.fromkeys(all_features))  # ×”×¡×¨×ª ×›×¤×™×œ×•×™×•×ª

# ×‘×“×™×§×ª ×¢××•×“×•×ª ×—×¡×¨×•×ª
missing_features = [f for f in all_features if f not in df.columns]
if missing_features:
    print("âš ï¸ ×”×¤×™×¦'×¨×™× ×”×‘××™× ×—×¡×¨×™× ×‘×“××˜×”:", missing_features)
    raise KeyError("ğŸ›‘ ×§×™×™××™× ×¤×™×¦'×¨×™× ×—×¡×¨×™× â€“ ××™ ××¤×©×¨ ×œ×××Ÿ ×›×›×” ××ª ×”××•×“×œ.")

# === 7. ×”×›× ×ª ×”× ×ª×•× ×™× ×œ××™××•×Ÿ ===
X = df[all_features].copy().apply(pd.to_numeric, errors="coerce").fillna(0)
y = df["success"]

bad_columns = [col for col in X.columns if not pd.api.types.is_numeric_dtype(X[col])]
if bad_columns:
    raise ValueError(f"ğŸ›‘ ×§×™×™××•×ª ×¢××•×“×•×ª ×œ× ××¡×¤×¨×™×•×ª â€“ {bad_columns}")

# === 8. ×¤×™×¦×•×œ ×œÖ¾Train/Test ===
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# === 9. ××™××•×Ÿ ××•×“×œ LightGBM ===
model = lgb.LGBMClassifier(
    learning_rate=0.02742,
    max_depth=-1,  # ××¤×©×¨ ×œ×”×©××™×¨ ×œ×œ× ×”×’×‘×œ×” ×× ×œ× ×¦×™×™× ×ª max_depth
    n_estimators=363,
    num_leaves=41,
    subsample=0.9615,
    colsample_bytree=0.91198,
    random_state=42
)
model.fit(X_train, y_train)

# === 10. ×”×¢×¨×›×ª ×‘×™×¦×•×¢×™× ===
y_pred_prob = model.predict_proba(X_test)[:, 1]
y_pred = (y_pred_prob >= 0.5).astype(int)

print("ğŸ¯ ×“×™×•×§:", accuracy_score(y_test, y_pred))
print("ğŸ“Š AUC:", roc_auc_score(y_test, y_pred_prob))
print("ğŸ“‹ ×“×•×´×—:")
print(classification_report(y_test, y_pred))

# === 11. ×©××™×¨×ª ×”××•×“×œ ×•×¨×©×™××ª ×”×¤×™×¦'×¨×™× ===
joblib.dump(model, "lightgbm_kickstarter_success_model.pkl")
with open("lightgbm_feature_columns.json", "w") as f:
    json.dump(all_features, f)

print("âœ… ×”××•×“×œ ×•×”×¤×™×¦'×¨×™× × ×©××¨×• ×‘×”×¦×œ×—×”.")
